{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed24f6e-7b47-41dd-98d7-5f2bf73d557b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 320\u001b[39m\n\u001b[32m    315\u001b[39m val_dir = \u001b[33m\"\u001b[39m\u001b[33mimages/val\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    317\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m train_transform = \u001b[43mtransform\u001b[49m.Compose([\n\u001b[32m    321\u001b[39m \n\u001b[32m    322\u001b[39m \n\u001b[32m    323\u001b[39m \n\u001b[32m    324\u001b[39m         transforms.ToTensor(),  \n\u001b[32m    325\u001b[39m ])\n\u001b[32m    328\u001b[39m val_transform = transform.Compose([ \n\u001b[32m    329\u001b[39m \n\u001b[32m    330\u001b[39m \n\u001b[32m    331\u001b[39m                 transforms.ToTensor(),  ])\n\u001b[32m    334\u001b[39m train_dataset = USDataset(train_csv, train_dir, transform=train_transform)\n",
      "\u001b[31mNameError\u001b[39m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Train Faster R-CNN on a custom dataset with Early Stopping (YOLO-style).\n",
    "Includes visualization of USAugment + Albumentations augmentations\n",
    "(original + individually labeled augmentations).\n",
    "\n",
    "Saves:\n",
    " - frcnn_losses.csv → training/validation losses per epoch\n",
    " - frcnn_metrics.csv → final evaluation metrics (mAP, precision, recall)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.ops import box_iou\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------- Dataset -----------------------------\n",
    "class USDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None, use_albumentations=True):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        bbox_cols = self.data.columns[2:6]\n",
    "        self.data[bbox_cols] = self.data[bbox_cols].apply(pd.to_numeric, errors=\"raise\")\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.use_albumentations = use_albumentations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.data.iloc[idx, 0])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"), dtype=np.float32) / 255.0\n",
    "        bbox = self.data.iloc[idx, 2:6].to_numpy(dtype=np.float32)\n",
    "        label = int(self.data.iloc[idx, 1])\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "        boxes = torch.tensor([bbox], dtype=torch.float32)\n",
    "        labels = torch.tensor([label], dtype=torch.int64)\n",
    "\n",
    "        return image, {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "\n",
    "class SmoothedValue:\n",
    "    def __init__(self, window_size=20, fmt=\"{median:.4f} ({global_avg:.4f})\"):\n",
    "        self.deque = deque(maxlen=window_size)\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "        self.fmt = fmt\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.deque.append(value)\n",
    "        self.count += n\n",
    "        self.total += value * n\n",
    "\n",
    "    @property\n",
    "    def median(self):\n",
    "        d = torch.tensor(list(self.deque))\n",
    "        return d.median().item()\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
    "        return d.mean().item()\n",
    "\n",
    "    @property\n",
    "    def global_avg(self):\n",
    "        return self.total / self.count if self.count > 0 else 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.fmt.format(\n",
    "            median=self.median,\n",
    "            avg=self.avg,\n",
    "            global_avg=self.global_avg\n",
    "        )\n",
    "\n",
    "\n",
    "class MetricLogger:\n",
    "    def __init__(self, delimiter=\"  \"):\n",
    "        self.meters = defaultdict(SmoothedValue)\n",
    "        self.delimiter = delimiter\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                v = v.item()\n",
    "            self.meters[k].update(v)\n",
    "\n",
    "    def log_every(self, iterable, print_freq, header=None):\n",
    "        i = 0\n",
    "        start_time = time.time()\n",
    "        header = header or \"\"\n",
    "\n",
    "        for obj in iterable:\n",
    "            yield obj\n",
    "            if i % print_freq == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                eta_seconds = elapsed / max(1, i + 1) * (len(iterable) - i - 1)\n",
    "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
    "\n",
    "                log = [header, f\"[{i}/{len(iterable)}]\", f\"eta: {eta_string}\"]\n",
    "                log += [f\"{name}: {meter}\" for name, meter in self.meters.items()]\n",
    "                print(self.delimiter.join(log))\n",
    "            i += 1\n",
    "\n",
    "\n",
    "# ----------------------------- Training -----------------------------\n",
    "def train_frcnn(model, train_loader, val_loader, optimizer, device, epochs=2):\n",
    "    \n",
    "    \n",
    "    train_losses, val_losses, mAP_50 = [], [],[]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch [{epoch + 1}/{epochs}]\")\n",
    "        metric_logger = MetricLogger()\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for images, targets in train_loader:\n",
    "            images = [img.to(device).float() for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            loss_dict = model(images, targets)\n",
    "            loss = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            metric_logger.update(\n",
    "                loss = loss.item(),\n",
    "                **{k:v.item() for k, v in loss_dict.items()}\n",
    "            )\n",
    "    \n",
    "        \n",
    "        \n",
    "        train_loss = metric_logger.meters[\"loss\"].global_avg\n",
    "        print(train_loss)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        metric = MeanAveragePrecision(box_format='xyxy', iou_type='bbox')\n",
    "        metric.to(device)\n",
    "       \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = [img.to(device).float() for img in images]\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                outputs = model(images)\n",
    "\n",
    "                for target, output in zip(targets, outputs):\n",
    "                    metric.update([output], [target])\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                metric_logger.update(\n",
    "                    loss = loss.item(),\n",
    "                    **{k:v.item() for k, v in loss_dict.items()}\n",
    "        )\n",
    "\n",
    "        results = metric.compute()\n",
    "        print(results)\n",
    "        map_50 = results[\"map_50\"]\n",
    "        print(\"All class mAP_50-->\",map_50)\n",
    "        \n",
    "        val_loss = metric_logger.meters[\"loss\"].global_avg\n",
    "        print(val_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "\n",
    "    loss_df = pd.DataFrame({\n",
    "                            \"epoch\": range(1,len(train_losses)+1),\n",
    "                            \"train loss\": train_losses,\n",
    "                            \"val loss\": val_losses,\n",
    "                            \"mAP_50\": map_50\n",
    "    })\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    return model, loss_df\n",
    "\n",
    "# ----------------------------- Evaluation -----------------------------\n",
    "def evaluate_frcnn(model, dataloader, num_classes=3, conf_thresh=0.25):\n",
    "    model.eval()\n",
    "    metric = MeanAveragePrecision(box_format='xyxy', iou_type='bbox')\n",
    "    metric.to(device)\n",
    "    \n",
    "   \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            images = [img.to(device).float() for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            outputs = model(images)\n",
    "\n",
    "            image1 = images[0].cpu().numpy()\n",
    "            #print(image1.shape)\n",
    "            image2 = np.transpose(image1,(1,2,0))\n",
    "            #print(image2.shape)\n",
    "            fig, ax = plt.subplots(1, figsize=(5,5))\n",
    "            ax.imshow(image2)\n",
    "            \n",
    "            for target, output in zip(targets, outputs):\n",
    "                    metric.update([output], [target])\n",
    "\n",
    "                    print(target[\"boxes\"])\n",
    "                    print(len(target))\n",
    "\n",
    "                    boxes1 = target[\"boxes\"].cpu().numpy()\n",
    "                    print(\"boxes1[0]-->\",boxes1[0])\n",
    "                    for box in boxes1:\n",
    "                                    x_min, y_min, x_max, y_max = box \n",
    "                                    width = x_max - x_min\n",
    "                                    height = y_max - y_min\n",
    "                                    \n",
    "                     \n",
    "                   \n",
    "                    rect = patches.Rectangle((x_min,y_min), width, height, linewidth=1,edgecolor=\"r\", facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "                \n",
    "                \n",
    "                     \n",
    "            plt.show()\n",
    "            break\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "           \n",
    "                                                                    \n",
    "\n",
    "        results = metric.compute()\n",
    "        print(results)\n",
    "        mAP_50 = results[\"map_50\"]\n",
    "        print(\"All class mAP_50-->\",mAP_50)\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "           \n",
    "\n",
    "    return mAP_50\n",
    "\n",
    "\n",
    "# ----------------------------- Run -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    train_csv = \"labels/frcnn_labels_train.csv\"\n",
    "    train_dir = \"images/train\"\n",
    "    val_csv = \"labels/frcnn_labels_val.csv\"\n",
    "    val_dir = \"images/val\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    \n",
    "    train_transform = transform.Compose([\n",
    "        \n",
    "        \n",
    "        \n",
    "            transforms.ToTensor(),  \n",
    "    ])\n",
    "       \n",
    "\n",
    "    val_transform = transform.Compose([ \n",
    "        \n",
    "        \n",
    "                    transforms.ToTensor(),  ])\n",
    "\n",
    "    \n",
    "    train_dataset = USDataset(train_csv, train_dir, transform=train_transform)\n",
    "    val_dataset = USDataset(val_csv, val_dir, transform=val_transform)\n",
    "    \n",
    "    for images, targets in train_dataset:\n",
    "        \n",
    "        \n",
    "        \n",
    "        image1 = images[0].cpu().numpy()\n",
    "            #print(image1.shape)\n",
    "        #image2 = np.transpose(image1,(1,2,0))\n",
    "        #print(image2.shape)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, figsize=(5,5))\n",
    "        ax.imshow(image1)\n",
    "            \n",
    "        \n",
    "\n",
    "        #print(target[\"boxes\"])\n",
    "        #print(len(target))\n",
    "        #for target in targets:\n",
    "        boxes1 = targets['boxes'].cpu().numpy()\n",
    "        boxes1 = boxes1[0]\n",
    "        #print(\"boxes_raw[0]-->\",boxes1)\n",
    "        x_min, y_min, x_max, y_max = boxes1\n",
    "        #print(x_min)\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "                                    \n",
    "                     \n",
    "                   \n",
    "        rect = patches.Rectangle((x_min,y_min), width, height, linewidth=1,edgecolor=\"r\", facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "                \n",
    "                \n",
    "                     \n",
    "        plt.show()\n",
    "        break\n",
    "\n",
    "    \n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "    print(len(train_loader))\n",
    "    print(train_loader)\n",
    "\n",
    "    num_classes = 3\n",
    "    model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.000025)\n",
    "\n",
    "    model, loss_df = train_frcnn(model, train_loader, val_loader, optimizer, device)\n",
    "\n",
    "    loss_df.to_csv(\"roboustness/frcnn_losses.csv\", index=False)\n",
    "    plt.figure (figsize=(8,5))   \n",
    "    plt.plot(loss_df[\"epoch\"], loss_df[\"train loss\"], label= \"Train Loss\", linestyle=\"-\")\n",
    "    plt.plot(loss_df[\"epoch\"], loss_df[\"val loss\"], label= \"Val Loss\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"No Aug\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "  \n",
    "    mAP_50 = evaluate_frcnn(model, val_loader)\n",
    "    \n",
    "    metrics = pd.DataFrame([{\n",
    "        \"mAP_50\": mAP_50\n",
    "        \n",
    "    }])\n",
    "    \n",
    "    metrics.to_csv(\"roboustness/frcnn_metrics.csv\", index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbd357-bd96-4f1d-affe-7b48aa5776a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
